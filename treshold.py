# -*- coding: utf-8 -*-
"""treshold.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ox8QnJjfqRCfV0kjyjGgJL4z8NV_MORb

FIRST TASK - FRUIT SEGMENTATION AND  DEFECT DETECTION - First Hint

Treshold the image by Otsu's Algorithm
"""

# A script that allows to treshold grayscale fruit's images in order to
# do a bimodularization of the image. 
import warnings
warnings.filterwarnings("ignore")
import sys
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
import matplotlib.image as mpimg
#for i in range()
img = cv.imread('C0_000001.png',0)
img_col = cv.imread('C1_000001.png',0)
# global thresholding
ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)
# Otsu's thresholding
ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)
# Otsu's thresholding after Gaussian filtering
blur = cv.GaussianBlur(img,(5,5),0)
ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)
# plot all the images and their histograms
images = [img, 0, th1,
          img, 0, th2,
          blur, 0, th3]
  
titles = ['Original  Image','Histogram','Global (v=127)',
          'Original  Image','Histogram',"Otsu",
          'Gaussian Image','Histogram',"Otsu"]
# It seems that the global tresholding is more accured on the details inside 
# the blobs (the defects), but Otsu's alg is the best approach to keep boards
for i in range(3):
    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')
    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])
    #Give more space to subplots
    plt.tight_layout()
    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)
    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])
    plt.tight_layout()
    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')
    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])
    plt.tight_layout()
plt.show()

# So let's consider only treshold by Otsu
plt.plot(3,3,6),plt.imshow(images[5],'gray');
plt.title(titles[5]), plt.xticks([]), plt.yticks([]);

"""Fill the holes by a fullfill approach"""

# Python program to demonstrate erosion and 
# dilation of images. 
import cv2 
import numpy as np 
from google.colab.patches import cv2_imshow

img_seg=images[5]
# Reading the input image 

# Taking a matrix of size 5 as the kernel 
kernel = np.ones((6,6), np.uint8) 

# The first parameter is the original image, 
# kernel is the matrix with which image is 
# convolved and third parameter is the number 
# of iterations, which will determine how much 
# you want to erode/dilate a given image. 
img_dilation = cv2.dilate(img_seg, kernel, iterations=2) 
img_dilation = cv2.erode(img_dilation, kernel, iterations=2) 
cv2_imshow( img_seg) 
cv2_imshow( img_dilation) 

#cv2.waitKey(0)

"""Generate the mask on bynarized image"""

# Generate the mask on gray-scale image
result = cv.bitwise_and(img,img_dilation)
result[img_dilation==0] = 255
from google.colab.patches import cv2_imshow
cv2_imshow( img)
cv2_imshow(result)
# Generate the mask on colored image
result2 = cv.bitwise_and(img_col,img_dilation)
result2[img_dilation==0] = 255
cv2_imshow(result2)


from google.colab.patches import cv2_imshow
img_col2 = mpimg.imread('C1_000001.png')
plt.axis('off')
plt.imshow(img_col2);

"""Second Hint"""

# Using the Canny filter to get contours
edges_high_thresh = cv2.Canny(result, 300, 500)
edges_normal = cv2.Canny(result,80,230)
my_edges = edges_normal - edges_high_thresh
# Stacking the images to print them together
# For comparison
image_canny = np.hstack((result, edges_high_thresh, edges_normal,my_edges))

# Display the resulting frame
cv2_imshow(image_canny)